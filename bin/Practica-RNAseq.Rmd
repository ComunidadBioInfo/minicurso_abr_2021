---
title: "Introdución a RNA-seq"
author: Ana BVA, Rodolfo
date: "`r BiocStyle::doc_date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
editor_options: 
  chunk_output_type: console
---

```{r}
## Checar el tiempo de cada chunk
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- difftime(Sys.time(), now)
      # return a character string to show the time
      paste("Tiempo: ", round(res, digits = 2))
    }
  }
}))

knitr::opts_chunk$set(time_it = TRUE)
```

# Descripción general

Este documento encontrarás el código que se ocupará en el mini curso de RNA-seq, 
el código usado para generar las [slides](https://github.com/ComunidadBioInfo/minicurso_abr_2021/tree/main/Slides) las puedes encontrar en [Github](https://github.com/ComunidadBioInfo/minicurso_abr_2021).

|    | [Tema](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#1)                                                         | [Práctica](https://comunidadbioinfo.github.io/minicurso_abr_2021/bin/Practica-RNAseq.html) | Tiempo (min) | Encargado |
|----|-------------------------------------------------------------|--------|--------------|-----------|
| 1  | [Introducción a RNA-seq](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#6)                                      | NA     | 5            | AnaB      |
| 2  | [Organización del proyecto (folder de datos, fig, scripts](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#12)   | NA     | 5            | Rodolfo   |
| 3  | [Flujo de trabajo para el análisis de RNA-seq](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#22)               | NA     | 5            | AnaB      |
| 4  | [Tipos de archivos](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#28])                                         | NA     | 5            | Rodolfo   |
| 5  | [Control de calidad de los datos](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#49)                            | Si     | 10           | AnaB      |
| 6  | [Alineamiento (Salmon)](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#63)                                      | Si     | 10           | Rodolfo   |
| 7  | [tximeta, tximport](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#80)                                          | Si     | 10           | AnaB      |
| 8  | [Objeto SummarizedExperiment en R](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#87)                           | Si     | 10           | Rodolfo   |
| 9  | [Normalización de los datos (RPKM, TPM)](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#100)                    | Si     | 15           | AnaB      |
| 10 | [Exploración de los datos](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#113)                                  | Si     | 15           | Rodolfo   |
| 11 | [DE (analysis)](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#152)                                             | Si     | 15           | AnaB      |
| 12 | [DE (visualization/resultados)](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#161)                             | Si     | 15           | Rodolfo   |


## Requisitos 

Está práctica está basada en Mike love vignette y ocuparemos los siguientes 
programas para analizar los datos del [GSE152699](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE152699).

## Experimento

Número de acceso GEO: GSE152699

```{r, out.width="800px", fig.align='center', echo=F}
knitr::include_graphics("../Slides/Images/Experiment_ver.png")
```


- [Descargar los datos que ocuparemos en está práctica](https://drive.google.com/file/d/1n8dQHFotDc-fHxrLZOPVFoS8D29Pf5SZ/view?usp=sharing)

- FastQC

- MultiQC (opcional)

- Salmon (opcional)

- R > 4.0 

- Rstudio

- Bioconductor >= 3.12

- Paquetería de R:


Analizar archivos crudos de RNAseq requiere poder de computo, si quieres hacer 
el análisis completo desde cero, necesitarás una computadora con al menos RAM 8 GB
y espacio para almacenar los archivos crudos (`.fastq`), aún así todo el proceso
puede tomar más tiempo del que tendremos en la práctica. Normalmente estos 
análisis se realizan en un cluster o servidor que suelen tener mayor capacidad 
que una laptop. Por lo que se verán los comandos para hacer el alineamiento en 
`Salmon`  pero **NO** correremos este paso. 

## Archivos

Si decides realizar toda la práctica necesitarás estos archivos. Descargar el archivo en formato zip llamado **Files.zip** desde este [vínculo](https://drive.google.com/file/d/1n8dQHFotDc-fHxrLZOPVFoS8D29Pf5SZ/view?usp=sharing) y colocalo en el folder principal de este repositiorio. Descomprime el archivo y sigue las indicaciones de los instructores.
En el archivo **Files.zip** encontrarás:

* `Archivos_fastq/`: Folder que contiene los archivos en formato .fastq
* `Salmon_quants/`: Folder que contiene las matrices de cuentas generadas por Salmon
* `genecode.v37.transcripts.fa`: Transcriptoma de referencia para realizar el alineamiento y conteo con Salmon
* `ObjetosR.RData`: Archivo de R que contiene los objetos de *SummarizedExperiment* y *DESeq* para realizar el análisis de expresión diferencial. **Descarga este [objeto](https://drive.google.com/file/d/1_j2Py3ifDRN-O_6ygq627xuKTAI2HmGb/view?usp=sharing) si no tienes suficiente espacio en tu computadora** 


## Instalación

<div class="alert alert-warning">
### Instalación de FastQC

1- Descargar el programa de su página web [fastQC](https://www.bioinformatics.babraham.ac.uk/projects/download.html#fastqc)

2- Hacer el archivo ejecutable

```{bash, eval= F, echo=TRUE}
chmod 755 /Applications/FastQC.app/Contents/MacOS/fastqc
ls -l /Applications/FastQC.app/Contents/MacOS/fastqc
```

3- Crear una liga simbolica para ejecutar `fastqc` desde cualquier ubicación

```{bash echo=TRUE, eval=FALSE}
ln -s /Applications/FastQC.app/Contents/MacOS/fastqc /usr/local/bin/fastqc
```

4- Correr `fastqc`

```{bash echo=TRUE, eval=FALSE}
fastqc --help
```
</div>

---

<div class="alert alert-warning">
### Instalación de MultiQC

Esta parte es opcional, pero si trabajas con RNA-seq te puede intersar. 
[MultiQC](https://multiqc.info/) es un programa que te perimte juntar los archivos de `fastQC`en uno 
solo y facilita su visualización.

- **Conda**: La instalación se puede hacer con conda, así que primero activamos un ambiente conda

```{bash echo=TRUE, eval=FALSE}
conda activate base
conda install -c bioconda -c conda-forge multiqc
```

- **Pip**: o con `pip`

```{bash echo=TRUE, eval=FALSE}
pip install multiqc
```


</div>

---

<div class="alert alert-warning">
### Instalación de Salmon

Descargar el archivo salmon-1.4.0_linux_x86_64.tar.gz
desde la página de [Salmon](https://github.com/COMBINE-lab/salmon/releases) y seguir
las instrucciones.

Si lo prefieres, la instalación la puedes realizar empleando conda:

```{bash, echo = T, eval = F}
#Descarga e instala el gestor de paquetes de python miniconda desde https://conda.io/projects/conda/en/latest/user-guide/install/index.html
conda activate miniconda
conda install -c bioconda salmon
```


</div>

---

<div class="alert alert-warning">
### Instalación de R y Rstudio

Puedes instalar [R](https://www.r-project.org/) a través de [Rstudio](https://www.rstudio.com/), asegurate de tener una versión de
R > 4.0. Puedes checar la versión de `R` que tienes si ejecutas `version` 
en tu consola de R:

```{r}
version
```
</div>

---

<div class="alert alert-warning">
### Instalación de Bioconductor

Durante esta práctica se usarán paqueterías que se enuentran en el repositorio 
de [Bioconductor](), usaremos `BiocManager` para instalar los diferentes paquetes
pero asegurate de tener la versión más actual de 


```{r eval=FALSE, include=TRUE}
# Instalar BiocManager
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

# Checar la versión
BiocManager::version()

# Si se requiere, se puede instalar la versión 3.12 manualmente
# BiocManager::install(version = "3.12")
```
</div>

---

<div class="alert alert-warning">
### Instalación de la paquetería de R

- Instalar la paquetería utilizando `BiocManager`

```{r eval=FALSE}
paquetes = c("DESeq2", "tximeta", "PCAtools", "SummarizedExperiment")
BiocManager::install()
```

- Adicionalmente, ocuparemos algunas funciones de `tidyverse` como la paquetería
de `ggplot2` y `pheatmap`. La instalaremos utilizando el repositorio de CRAN

```{r eval=FALSE}
install.packages(c('tidyverse','pheatmap'))
```

</div>


---
# 2: Organización del proyecto

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#12)

```{r, out.width="450px", fig.align='center', echo = F}
knitr::include_graphics("../Slides/Images/Proyecto.png")
```

## Experimento

Número de acceso GEO: GSE152699

```{r, out.width="800px", fig.align='center', echo=F}
knitr::include_graphics("../Slides/Images/Experiment_ver.png")
```


# 3: Flujo de trabajo para el análisis de RNA-seq

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#22)

En este mini curso veremos brevemente como analizar datos de RNA-seq, tendremos 
una breve introdución a RNA-seq, así como los pasos a seguir en el análisis bioinformático
(como se observa en el diagrama).

```{r, out.width = "550px",fig.align='center'}
knitr::include_graphics("https://biocorecrg.github.io/RNAseq_course_2019/images/RNAseq_workflow.png")
```

Imagen tomada de [BiCore RNAseq course 2019](https://biocorecrg.github.io/RNAseq_course_2019/salmon.html)


---

# 5: Control de calidad de los datos

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#28)

Muchas veces a esté paso se le conoce como *QC (Quality Check)*.


## Pasos para correr FastQC:

1- Checar los datos fastq
```{bash echo=TRUE, eval=FALSE}
pwd
ls data/Archivos_fastq
```


2- Crear un directorio para guardar el output

```{bash echo=TRUE, eval=FALSE}
mkdir Output/FastQC
```

3- Correr `FastQC`

```{bash echo=TRUE, eval=FALSE}
# la opción -o es para elejir el directorio de salida
fastqc data/Archivos_fastq/*.fastq.gz -o Output/FastQC/
```

4- Checar los archivos generados

```{bash echo=TRUE, eval=FALSE}
ls Output/FastQC
```


## MultiQC

[MultiQC](https://multiqc.info/) te permite juntar los output en un solo archivo y poder visualizarlos mejor.

*Esta parte es opcional, pero si trabajas con RNA-seq te puede intersar.

1. Instalar `MultiQC`

2. Correr MultiQC

```{bash multiqc, echo=TRUE, eval=FALSE}
cd Output/.
multiQC FastQC/ -o MultiQC/
```

3. Checar el [output.html](https://comunidadbioinfo.github.io/minicurso_abr_2021/Output/MultiQC/multiqc_report.html)

---

# 6: Alineamiento (Salmon)

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#63)

Si deseas realizar el pseudo-alineamiento con `Salmon` 
te recomendamos descargar los archivos `.fastq` de las líneas celulares así como el
archivo `.fasta` del transcriptoma humano. 

## Generar índice del transcriptoma

<div class="alert alert-warning">
Para ello vamos a requerir:

- Archivo **Fasta** del transcriptoma de referencia del humano. Descargado del sitio de [GeneCode](https://www.gencodegenes.org/human/). Lo pueden encontrar en el folder de `Reference/`

</div>

 Código para genear el índice

`-t`: Ubicación al archivo Fasta del transcriptoma

`-i`: Ubicación para salvar el índice

`--genecode`: El Fasta del transcriptoma de referencia está en formato de GENECODE

```{bash engine.opts = '-l', eval = F}
salmon index -t ../transcriptome/gencode.v37.transcripts.fa.gz -i ../transcriptome/genecode.v37.salmon141 -p 6
```


## Cuantificar la abundancia de los transcritos

<div class="alert alert-warning">
Requerimientos:

- Archivos **Fastq** de las lecturas -> Paired end R1 y R2

Ubicados en el folder de `data`

- Índice generado en el paso anterior
</div>

Código para producir cuantificar los transcritos


`-i`: Ubicación del índice

`-l`: Tipo de librería

`-1 y -2`: Ubicación a las lecturas R1 y R2

`-o`: Ubicación para almacenar los resultados


```{bash engine.opts = '-l', eval = F}
##Crear un directorio para almacenar los datos de los conteos
mkdir -p ../salmon_quant
##Llamar salmon para realizar el conteo
salmon quant -i ../transcriptome/genecode.v37.salmon141 \
             -l A \
             -1 ../Data/s1_R1.fastq.gz -2 ../Data/s1_R2.fastq.gz \
             -p 6 --validateMappings \
             -o ../salmon_quant/s1_quant
```


---

# 7: Tximeta

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#80)


```{r, out.width = "650px",fig.align='center'}
knitr::include_graphics("https://journals.plos.org/ploscompbiol/article/figure/image?size=large&id=10.1371/journal.pcbi.1007664.g001")
```
 

[Love, Michael I., et al. "Tximeta: Reference sequence checksums for provenance identification in RNA-seq." PLoS computational biology 16.2 (2020): e1007664.](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007664)


<div class="alert alert-warning">
## Instalación de tximeta

Instalar `tximeta` desde R usando `BiocManager`

```{r eval=FALSE, include=TRUE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

# Puedes instalar la paqueteria de tximeta usando BiocManager::install() 
BiocManager::install("tximeta")
```
</div>


## Importar datos

Utilizamos `tximeta` para importar los datos. 

<div class="alert alert-danger">

Nota: `tximeta` espera dos columnas:

  - `files`: con la rut a `quant.sf`
  
  - `names`: con los nombres de las muestras

</div>

Importamos la información de cada muestra

```{r echo=TRUE}
# Leemos los datos
coldata <- read.delim(here::here("output/salmon_quants/metadata.txt"))

# Generamos la columna "names"
# info$names <- info$Unique_id # Puedes agregar una columna nueva
coldata <- dplyr::rename(coldata, names = unique_id) # Renombrar la columna 
rownames(coldata) <- coldata$names
coldata
```

Ahora las cuentas generadas por `Salmon`

```{r echo=TRUE}
# Ubicamos el dir de trabajo
dir <- file.path(here::here("output/salmon_quants"))
#Checamos que esten los folders  
list.files(dir) 

# Que hacemos aqui??  Checar
# file.path(dir,paste0(info$Sample,"_quant"),"quant.sf")
coldata$files <- file.path(dir,paste0(coldata$Sample,"_quant"),"quant.sf")

#Checamos que los archivos existan
data.frame(coldata$Sample, file.exists(coldata$files))
```

Importar los datos usando `tximeta` 

```{r echo=TRUE}
# Importamos la paqueteria 
library(tximeta)

# Checamos que el df tenga la columna "names" y "files"
coldata

# Generamos el objeto usando tximeta()
se <- tximeta(coldata)
```

```{r, eval=F}
# Opción si no funciona tximeta
#load("../data/ObjetosR.RData")
```


---

# 8: Objeto SummarizedExperiment en R

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#87)

```{r, out.width="700px", echo=FALSE}
knitr::include_graphics("../Slides/Images/Summarized_experiment.png")
```

```{r message=FALSE, warning=FALSE}
library(SummarizedExperiment)
```

```{r}
se
```

## ColData

El cajón o slot correspondiente a `ColData` contiene la tabla de metadatos creada para importar las cuentas con tximeta. 

Para acceder a **ColData** usar el siguiente comando:

```{r}
colData(se)
```

El slot **ColData** es un objeto con clase de *DataFrame*

```{r}
class(colData(se))
```

*Rownames* de **ColData** corresponden a los *Colnames* en el slot **Assay**- **Importante para análisis con DESeq2**

```{r}
rownames(colData(se))
```

## rowRanges

El cajón de `rowRanges` hace referencia a las coordenadas de cada transcrito

Para acceder al **rowRanges** usar:

```{r}
rowRanges(se)
```

El cajón **rowRanges** almacena metadatos de cada secuencia (en este caso cromosomas)

```{r}
seqinfo(rowRanges(se))
```

## Assay

El slot `assay` almacena la información de las cuentas para cada transcrito dividida en tres niveles:

```{r}
assayNames(se)
```

Para acceder a la matriz de cuentas estimadas por **Salmon**, correr:

```{r}
head(assay(se), 5)
```

Las matriz de abundancia *(TPM)* puede obtenerse:

```{r}
## Obtener matriz de TPM
head(se@assays@data$abundance, 5)
```


## ¿Recuerdan a qué tiene que ser igual *Rownames* del slot colData?


```{r}
rownames(colData(se))
```

```{r, include=F, echo=T}
colnames(assay(se))
```

```{r}
## Comprobar que rownames de colData es igual a colnames de assay
row.names(colData(se)) == colnames(assay(se))
```


---

# 9: Normalización de los datos (RPKM, TPM)

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#100)


- Es el primer paso del análisis de expresión diferencial y es necesario para hacer comparaciones acertadas entre muestras. 

- Las cuentas crudas están conformadas por un componente "interesante" (la expresión de RNA) y componentes "no interesantes" (como los batch effects, ruido de la plataforma, etc.).

- La normalzación escala las cuentas para tratar de reducir los componentes "no interesantes" y poder comparar las muestras entre si. 

<div class="alert alert-info">
## Métodos comunes

| Método de normalización | Descripción | Factores de evaluación | Recomendaciones de uso |
|:-----------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------------:|
| CPM (cuentas por millón): cuentas escalados por el número total de lecturas | Profundidad de secuenciación | Comparaciones de cuentas de genes entre réplicas del mismo grupo de muestras| NO para comparaciones dentro de la muestra o análisis de DE.| 
| TPM (transcritos por millón de lecturas): cuentas escalados por el número total de lecturas  | Profundidad de secuenciación | Comparaciones de cuentas de genes entre réplicas del mismo grupo de muestras | NO para análisis de DE. |
| RPKM/FPKM (lecturas/fragmentos por kilobase de exón por millón de lecturas/fragmentos mapeados| Similar a TPM, profundidad de secuenciación y longitud del gen | Comparaciones de cuentas entre genes dentro de una muestra | NO para comparaciones entre muestras o análisis de DE.|
| Factor de normalización de DESeq2 | Cuentas divididas por factores de tamaño específicos de la muestra determinados por la mediana del ratio de cuentas de genes en relación con la media geométrica por gen | Profundidad de secuenciación y composición del RNA | Comparaciones de cuentas de genes entre muestras y para el análisis de DE; NO para comparaciones dentro de la muestra |
| La media cortada de los valores M de EdgeR (TMM) | Utiliza una media recortada ponderada de los ratios de expresión logarítmica entre las muestras | Profundidad de secuenciación | Composición de RNA y longitud de los genes. |


[Tabla tomada de Intro to DGE](https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html)

</div>

## DESeq2

- Normalización para análisis de expresión diferencial:

  - Factor de normalización de `DESeq2`

- Normalización para visualización u otras aplicaciones:

  - Variance stabilizing transformation (VST)
  
  - Regularized-logarithm transformation (rlog)


`DESeq2`ajusta a un modelo lineal generalizado (GLM) de la familia binomial negativa (NB).

```{r include=FALSE}
library(tidyverse)
```

## Factor de normalización en DESeq2

Ejemplo de como se calcula el factor de normalización en DESeq2.

Primero generamos una tabla con cuentas simuladas

```{r}
# tabla con cuentas 
df <- tibble(gene = c("gene1", "gene2"),
                 muestraA = c(1749, 35),
                 muestraB = c(943, 29)
                 )
df
```

1. Crea una pseudo-referencia por muestra (promedio geometrico por fila) `sqrt(muestraA * muestra B)`

```{r}
# Calcular el promedio geometrico
df <- df %>%
  rowwise() %>% 
  mutate(prom_geom = sqrt(muestraA * muestraB))
df
```

2. Se calcula la fración `muestra/pseudo-referencia`

```{r}
# Dividir las cuentas entre el promedio geometrico
df <- df %>% 
  rowwise() %>% 
  mutate(muestraA_pseudo_ref = muestraA / prom_geom) %>% 
  mutate(muestraB_pseudo_ref = muestraB / prom_geom)

df
```

3. Se calcula un factor de normalización (size factor) utilizando la `median` por columnas.

```{r}
# Se calcula el factor de normalizacion usando la mediana para cada muestra
norm_factor_muestraA <- median(df$muestraA_pseudo_ref)
norm_factor_muestraA

# Repetimos el proceso para la muestra B
norm_factor_muestraB <- median(df$muestraB_pseudo_ref)
norm_factor_muestraB

```

4. Se dividen las `cuentas crudas/size factor` para calcular las cuentas normalizadas.

```{r}
# Columnas con las cuentas crudas
df %>% 
  select(gene, muestraA, muestraB)

# Dividir las cuentras entre el factor de normalización
df$norm_muestraA <- df$muestraA/norm_factor_muestraA
df$norm_muestraB <- df$muestraB/norm_factor_muestraB

# Columnas con las cuentas normalizadas
df %>%  
  select(norm_muestraA, norm_muestraB)
```

## Ejercicio 

Se pueden ocupar otras transformaciones en la paquetería de `DESeq2`pero no son las mas recomendadas para DE. 

Para normalizar, primero construimos el objeto `DESeqDataSet`, para ello necesitamos definir el modelo de DE (Quienes son Controles y quienes tratamiento). 


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Importamos las librerías que necesitemos
library("DESeq2")
library("dplyr")
library("ggplot2")
library("vsn")
```

```{r echo=TRUE}
# Definir los grupos que se desean comparar
se$Treatment <- factor(se$Treatment)

# Checar cantidad de muestras
table(se$Treatment)

# Generar el objeto de DESeq 
dds <- DESeqDataSet(se, design = ~ Treatment)

# Prefiltrado para quitar genes con cuentas bajas
keep <- rowSums(counts(dds) >= 3) >= 6
dds <- dds[keep, ]

# Funcion que normaliza los datos y realiza el analisis de expresión differencial
dds <- DESeq(dds)
```


## Otras transformaciones

Puedes realizar otras transformaciones en `DESeq2` para estabilizar la varianza a través de los differentes valores promedio de expresión.  

```{r}
# Grafica de cuentas crudas
meanSdPlot(counts(dds), ranks = F)

# Gráfica de cuentas en escala log2
meanSdPlot(log2(counts(dds) +1), ranks = F)
```


```{r echo=TRUE}
# variance stabilizing transformation (VST), (Anders and Huber 2010)
vsd <- vst(dds, blind = FALSE)
head(assay(vsd), 3)

# regularized-logarithm transformation (rlog), (Love, Huber, and Anders 2014)
rld <- rlog(dds, blind = FALSE)
head(assay(rld), 3)

# Normalización con el factor de normalizacion 
dds <- estimateSizeFactors(dds)

# Juntar los datos de las tres normalizaciones
df <- bind_rows(
  as_data_frame(log2(counts(dds, normalized=TRUE)[, 1:2]+1)) %>%
         mutate(transformation = "log2(x + 1)"),
  as_data_frame(assay(vsd)[, 1:2]) %>% mutate(transformation = "vst"),
  as_data_frame(assay(rld)[, 1:2]) %>% mutate(transformation = "rlog"))
  
# Renombrar columnas
colnames(df)[1:2] <- c("x", "y")  

# Nombre de las graficas
lvls <- c("log2(x + 1)", "vst", "rlog")

# Agrupar los tres tipos de normalizacion en grupos como factores
df$transformation <- factor(df$transformation, levels=lvls)

# Plotear los datos
ggplot(df, aes(x = x, y = y)) + geom_hex(bins = 80) +
  coord_fixed() + facet_grid( . ~ transformation)  

```



---

# 10: Exploración de los datos

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#113) 

## PCA

- Análisis de componentes principales

- Método algebraico para reducir la dimensionalidad de sets de datos complejos (múltiples variables)

- Reducción de dimensionalidad o variables permite un análisis exploratorio más intuitivo

- Reducción de variables implica  preservar y captar la mayor información sobre los datos

## ¿Cómo crear nuestro propio PCA?

Primero instalen las siguientes librerías:

```{r}
library(DESeq2)
library(PCAtools)
```

Usemos la siguiente normalización logarítmica de las cuentas (toma en cuenta el tamaño de 
```{r}
## Transformación recomendada para sets de con menos de 30 muestras
rld <- rlog(dds, blind = F)
```

- Usemos la función interna de *DESeq2* para graficar nuestro PCA:

```{r}
## El argumento intgroup permite especificar mediante cuál variable colorear los datos
plotPCA(rld, intgroup = "Treatment")
```


- Con la librería de *PCAtools*:

```{r}
## Crear un objeto que contenga los datos del PCA
PCA <- pca(assay(rld), scale = T, metadata = colData(rld)) 
## Graficar en 2D los resultados
biplot(PCA, colby = "Treatment")
## Generar un screeplot para visualizar la varianza asociada a cada componente
screeplot(PCA)
```

## ¿Cómo ven los resultados?

```{r, out.width= "350px", fig.align='center'}
plotPCA(rld, intgroup = "Treatment")+
  geom_label_repel(aes(label = colnames(assay(rld))), 
                   segment.color = "grey50", 
                   box.padding = 0.35, 
                   point.padding = 0.5)
```


```{r, out.width="350px", fig.align='center'}
biplot(PCA, lab = colnames(assay(rld)), colby = "Treatment", legendPosition = "right")
```

---

# 11: Análisis de expresión diferencial

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#152)

Paso para obtener cuales son los genes que varían entre las condiciones

```{r, out.width = "750px",fig.align='center'}
knitr::include_graphics("https://raw.githubusercontent.com/hbctraining/DGE_workshop/master/img/de_theory.png")
```

[Imagen tomada de Intro to DGE](https://github.com/hbctraining/DGE_workshop)

Recordemos el objeto que creeamos

```{r echo=TRUE}
# Checar objeto generado 
dds
```

Para ver los resultados podemos usar la función `results`

```{r}
# Obtener los resultados del DE
res <- results(dds)
res
summary(res)
```

Para ver que hay en cada columna:
```{r}
mcols(res, use.names = TRUE)
```

Podemos hacer cortes:
```{r}
resLFC1 <- results(dds, lfcThreshold=1)
table(resLFC1$padj < 0.1)
```



# 12: Visualización de los resultados

[Slides](https://comunidadbioinfo.github.io/minicurso_abr_2021/Slides/Slides.html#161) 

## MAplot

 Gráfico que representa la distribución de los genes o transcritos en las comparaciones de interés


```{r}
res_lfc <- lfcShrink(dds, coef = "Treatment_Verafinib_vs_Control",  type = "apeglm")
group <- coldata$Treatment
dds$group <- group
```


```{r}
##Es importante que recuerden que la hipótesis nula que se probó fue
##"El lfc del gen n es igual a 0" por lo tanto los genes coloreados son...
plotMA(res)
```

También pueden generar un MAplot interactivo con la librería de *Glimma*
```{r, eval=FALSE}
library(Glimma)
glimmaMA(dds)
```

## Volcano plot

De manera similar al MAplot con el volcano plot visualizamos los genes que muestran expresión diferencial en nuestra condición de interés

- En el eje y se grafica el -log10 de padj

- En el eje x se grafica el lfc o *log2foldchange*


```{r}
##Para crear un volcano plot necesitas convertir los resultados de DESeq a un data frame
DEG <- as.data.frame(res)
##En el script de funciones encontrarás la función de volcanoplotR para generar tu gráfico
#los valores de los argumentos logfc y p.adj deben ser iguales al threshold utilizado para generar los resultados
#en type debes indicar que los resultados provienen de DESeq
source("./functions.R")
volcanoplotR(DEG, logfc = 0, p.adj = 0.1, type = "DESeq")
```


## Heatmap

El *heatmap* nos permite visualizar la expresión de los genes diferencialmente expresados en terminos de las cuentas normalizadas

Consideraciones:

- Usar los valores de las cuentas normalizadas para una mejor comparación entre muestras

- Escalar los valores de las cuentas (renglones) para visualizar las diferencias en la expresión

Usaremos la librería de *pheatmap*

```{r, eval = T}
library(pheatmap)

##Guardar la lista de transcritos que mostraron expresión diferencial significativa
significant <- DEG %>% filter(log2FoldChange > 0 & padj < 0.1 |
                                   log2FoldChange < 0 & padj < 0.1)
##Generar la matriz de cuentas normalizadas
norm_counts <- counts(dds, normalized = T)
##Cortar la matriz de cuentas normalizadas con los id de los transcritos diferencialmente expresados
norm_counts <- norm_counts[rownames(significant), ]
##Generar una tabla de anotaciones preservando el tratamiento y el tipo de células
annotation_col <- coldata[, c("names","Cell", "Treatment")]
##Generar el heatmap empleando clustering jerarquico
pheatmap(norm_counts, 
         border_color = NA, 
         scale = "row",
         clustering_distance_rows = "euclidean", 
         clustering_distance_cols = "euclidean", 
         clustering_method = "average", 
         show_colnames = F, 
         show_rownames = F, 
         annotation_col = annotation_col)
```

```{r}
library(pheatmap)
pheatmap(norm_counts, 
         border_color = NA, 
         scale = "row",
         clustering_distance_rows = "euclidean", 
         clustering_distance_cols = "euclidean", 
         clustering_method = "average", 
         show_colnames = F, 
         show_rownames = F, 
         annotation_col = annotation_col)
```



# Paquetería

```{r}
sessionInfo()
```



